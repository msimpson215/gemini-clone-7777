<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Minimal VoxTalk (OpenAI-only)</title>
</head>
<body>
  <button id="startBtn">▶ Start Talking</button>
  <audio id="remote" autoplay playsinline></audio>

<script>
const startBtn = document.getElementById("startBtn");
const rtAudio = document.getElementById("remote");

async function init() {
  startBtn.disabled = true;

  // Get session from server.js
  const s = await fetch("/session", { method: "POST" });
  const { client_secret, model, voice } = await s.json();

  // WebRTC connection
  const pc = new RTCPeerConnection();
  pc.ontrack = (ev) => { rtAudio.srcObject = ev.streams[0]; };

  // Data channel for sending events/instructions
  const dc = pc.createDataChannel("oai-events");

  // Offer → OpenAI
  const offer = await pc.createOffer({ offerToReceiveAudio: true });
  await pc.setLocalDescription(offer);
  const r = await fetch(`https://api.openai.com/v1/realtime?model=${model}&voice=${voice}`, {
    method: "POST",
    headers: { Authorization: `Bearer ${client_secret.value}`, "Content-Type": "application/sdp" },
    body: offer.sdp
  });
  const answer = { type: "answer", sdp: await r.text() };
  await pc.setRemoteDescription(answer);

  // Mic input → send to OpenAI directly
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  const micTrack = stream.getTracks()[0];
  pc.addTrack(micTrack, stream);

  // Optional: send manual instructions via data channel
  dc.onopen = () => {
    console.log("Data channel open, ready for instructions");
  };
}

startBtn.onclick = init;
</script>
</body>
</html>
